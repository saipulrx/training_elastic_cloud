# Snippet for Day 4 Module 4 Elasticsearch Vector Search

## <em>Quick links to the recipes</em>
* [Using Cosine Similarity](#using-cosine-similarity)
* [Using dot product Similarity](#using-dot-product-similarity)
* [Using L2 Norm Similarity](#using-l2-norm-similarity)
* [Semantic Search](#semantic-search)

## Using Cosine Similarity
There are 4 step to use cosine similarity in elasticsearch :
### Generate embedding value
For generate embedding value using python, you can use various pre-trained models like those available in the Hugging Face Transformers library or specialized embedding models such as Sentence-Transformers. These models convert text into numerical vector representations (embeddings) that can be used for similarity search, semantic search, or other machine learning tasks.

Hereâ€™s a step-by-step guide on how to generate embeddings using Python:

#### Step 1: Install Required Libraries
Make sure you have the necessary libraries installed:  
```
pip install torch transformers sentence-transformers
```
- torch: Required for running PyTorch models.
- transformers: Provides access to pre-trained models from Hugging Face.
- sentence-transformers: Offers high-quality models optimized for generating embeddings.

#### Step 2: Using Sentence-Transformers for Simpler and Better Embeddings
```
from sentence_transformers import SentenceTransformer
import json

# Load a pre-trained Sentence Transformer model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Example text
text = ["This is the first sentence."]

# Generate embeddings
embeddings = model.encode(text)

# Print embeddings
print("Embedding shape:", embeddings.shape)
print(embeddings[0])

doc = {"sentence": text[0], "vector": embeddings[0].tolist()}
print(json.dumps(doc, indent=2))
```

### Create index with a dense_vector Field
Run script bellow in Dev Tools
```
PUT vector_index
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "description": {
        "type": "text"
      },
      "embedding": {
        "type": "dense_vector",
        "dims": 384
      }
    }
  }
}
```

### Add documents with include embedding value from step 1
Run script bellow in Dev Tools
```
POST vector_index/_doc/1
{
  "title": "Example Document",
  "description": "This is a sample description.",
  "embedding": [
    0.09857464581727982,
    0.0569785013794899,
    ...,
    0.04203876480460167,
    -0.07103762030601501
  ]
}
```

### Run query dense vector use cosine similarity
Run script bellow in Dev Tools
```
GET vector_index/_search
{
  "query": {
    "script_score": {
      "query": {
        "match_all": {}
      },
      "script": {
        "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
        "params": {
          "query_vector": [
            0.09857464581727982,
            0.0569785013794899,
            ...,
            0.04203876480460167,
            -0.07103762030601501
            ]
        }
      }
    }
  }
}
```
For python script, please refer to [this notebook](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/04-multilingual.ipynb)

## Using dot product Similarity
For using dot product Similarity is same with Cosine and only different just query dot product similarity

### Run query dense vector use dot product similarity
Run script bellow in Dev Tools
```
GET vector_index/_search
{
  "query": {
    "script_score": {
      "query": {
        "match_all": {}
      },
      "script": {
        "source": """
        double value = dotProduct(params.query_vector, 'embedding');
        return sigmoid(1, Math.E, -value);
        """,
        "params": {
          "query_vector": [
            0.09857464581727982,
            0.0569785013794899,
            ...,
            0.04203876480460167,
            -0.07103762030601501
            ]
        }
      }
    }
  }
}
```

## Using L2 Norm Similarity
For using L2 Norm Similarity is same with Cosine and only different just query L2 Norm similarity

### Run query dense vector use L2 Norm similarity
Run script bellow in Dev Tools
```
GET vector_index/_search
{
  "query": {
    "script_score": {
      "query": {
        "match_all": {}
      },
      "script": {
        "source": "1 / (1 + l2norm(params.queryVector, 'my_dense_vector'))",
        "params": {
          "query_vector": [
            0.09857464581727982,
            0.0569785013794899,
            ...,
            0.04203876480460167,
            -0.07103762030601501
            ]
        }
      }
    }
  }
}
```

## Semantic Search
- For example semantic search with use simple data, please see run [semantic_search_example.py]()
- For example semantic search with use case semantic text, please refer to [this notebook](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/09-semantic-text.ipynb#scrollTo=24f0133923553d28) 